{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d2d9e34",
   "metadata": {},
   "source": [
    "# Streamlining Data Management: Uploading and Managing Datasets with Amazon S3\n",
    "Introduction\n",
    "In today's data-driven environment, efficient management and accessibility of datasets are crucial for any analytical or machine learning task. Utilizing cloud storage solutions such as Amazon S3 (Simple Storage Service) can significantly enhance data management practices by providing scalable, secure, and robust storage options. This guide explores how to effectively use Amazon S3 for uploading and managing datasets, particularly focusing on a scenario involving a dataset of mushroom characteristics. The example outlines the steps for uploading a CSV file to S3, verifying the upload, and managing the dataset within the S3 infrastructure.\n",
    "\n",
    "Detailed Explanation\n",
    "Preparation and Uploading\n",
    "The process begins by acquiring the dataset, in this case, a comprehensive list of mushroom attributes that could be used for species classification or similar biological studies. The dataset is initially loaded into a suitable data manipulation tool where it can be preprocessed or inspected before uploading.\n",
    "\n",
    "Uploading to Amazon S3\n",
    "Once the dataset is ready, it is uploaded to an Amazon S3 bucket. S3 buckets are the basic containers in AWS where data is stored. The upload involves converting the dataset into a format compatible with S3 (e.g., a CSV file) and then transferring it using secure methods that ensure data integrity and privacy.\n",
    "\n",
    "Post-Upload Verification\n",
    "After the dataset is uploaded to the cloud, it's essential to verify the upload to ensure that the data has been correctly and fully transferred. This step might include checking the dataset's presence in the bucket and reviewing its size and timestamp to confirm that the latest version is uploaded.\n",
    "\n",
    "Data Management in S3\n",
    "Managing data within S3 includes tasks such as listing the available datasets, organizing them into folders or applying tags for easier access, and setting permissions to control access. Additionally, S3 provides features to handle large datasets efficiently, such as lifecycle policies for archiving old data and versioning to keep track of changes.\n",
    "\n",
    "Utilization\n",
    "With the dataset securely uploaded and managed in S3, it can be readily accessed and utilized for various purposes. Analysts and data scientists can connect to the S3 bucket from their data processing applications to load the dataset into analytical tools, ensuring that the most recent data is always used in their analyses.\n",
    "\n",
    "This workflow not only secures the data but also makes it highly accessible and manageable, streamlining the data handling process and supporting a wide range of data-intensive applications in a cost-effective manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "447d8464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  type cap_shape cap_surface cap_color bruises odor gill_attachment  \\\n",
      "0    p         x           s         n       t    p               f   \n",
      "1    e         x           s         y       t    a               f   \n",
      "2    e         b           s         w       t    l               f   \n",
      "3    p         x           y         w       t    p               f   \n",
      "4    e         x           s         g       f    n               f   \n",
      "\n",
      "  gill_spacing gill_size gill_color  ... stalk_surface_below_ring  \\\n",
      "0            c         n          k  ...                        s   \n",
      "1            c         b          k  ...                        s   \n",
      "2            c         b          n  ...                        s   \n",
      "3            c         n          n  ...                        s   \n",
      "4            w         b          k  ...                        s   \n",
      "\n",
      "  stalk_color_above_ring stalk_color_below_ring veil_type veil_color  \\\n",
      "0                      w                      w         p          w   \n",
      "1                      w                      w         p          w   \n",
      "2                      w                      w         p          w   \n",
      "3                      w                      w         p          w   \n",
      "4                      w                      w         p          w   \n",
      "\n",
      "  ring_number ring_type spore_print_color population habitat  \n",
      "0           o         p                 k          s       u  \n",
      "1           o         p                 n          n       g  \n",
      "2           o         p                 n          n       m  \n",
      "3           o         p                 k          s       u  \n",
      "4           o         e                 n          a       g  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://github.com/stedy/Machine-Learning-with-R-datasets/raw/master/mushrooms.csv'\n",
    "mushroom_df = pd.read_csv(url)\n",
    "print(mushroom_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c286bc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'Y9WW43W6W20Y3VJV',\n",
       "  'HostId': '7/xNgH2eIi+caXqUuyxWnZ4BrRDVWFJiw3NgvP4kbuiiKGkwHewAZE7nrmKyKbsAsRCGClb9gQI=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '7/xNgH2eIi+caXqUuyxWnZ4BrRDVWFJiw3NgvP4kbuiiKGkwHewAZE7nrmKyKbsAsRCGClb9gQI=',\n",
       "   'x-amz-request-id': 'Y9WW43W6W20Y3VJV',\n",
       "   'date': 'Thu, 06 Apr 2023 17:35:16 GMT',\n",
       "   'location': '/informationarchvijayasuriyasureshassignment8a',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Location': '/informationarchvijayasuriyasureshassignment8a'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://github.com/stedy/Machine-Learning-with-R-datasets/raw/master/mushrooms.csv'\n",
    "mushroom_df = pd.read_csv(url)\n",
    "print(mushroom_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f23053f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "def upload_s3(df,i):\n",
    "    global s3,bucket_name\n",
    "    csv_buf = StringIO()\n",
    "    df.to_csv(csv_buf,header=True,index=False)\n",
    "    csv_buf.seek(0)\n",
    "    s3.put_object(Bucket=bucket_name,Body=csv_buf.getvalue(),Key=i)\n",
    "\n",
    "# Check if the bucket exists\n",
    "response = s3.list_buckets()\n",
    "buckets = [bucket['Name'] for bucket in response['Buckets']]\n",
    "if bucket_name not in buckets:\n",
    "    print(f\"{bucket_name} bucket does not exist.\")\n",
    "else:\n",
    "    upload_s3(mushroom_df, 'classic_mushroom_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0d937d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classic_mushroom_data.csv\n"
     ]
    }
   ],
   "source": [
    "# list objects in S3 bucket\n",
    "response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "for object in response['Contents']:\n",
    "    print(object['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c97c330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
